{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies**"
      ],
      "metadata": {
        "id": "XO-b2ZVfBSqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the required packages\n",
        "!pip install -q scikit-learn pandas xgboost joblib\n",
        "print(\"Dependencies installed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MU5cP30_x-p",
        "outputId": "f98a23eb-f550-46c4-c61a-60c0ad716d60"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading dataset**"
      ],
      "metadata": {
        "id": "W5fa1r8NBXNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading the dataset\n",
        "from pathlib import Path\n",
        "file_candidates = list(Path.cwd().glob(\"*breast*.*\")) + list(Path.cwd().glob(\"*.data\")) + list(Path.cwd().glob(\"*.csv\"))\n",
        "if file_candidates:\n",
        "    print(\"Found candidate data files in working directory:\")\n",
        "    for f in file_candidates:\n",
        "        print(\" -\", f.name)\n",
        "else:\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"No dataset found. Please upload your dataset file (e.g., 'breast-cancer-wisconsin.data' or 'Breast_Cancer_Data.csv').\")\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded:\n",
        "            print(\"Uploaded:\", fn)\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"No dataset found. Please upload the dataset file to the Colab environment.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D6cEX1__zmk",
        "outputId": "09057f71-0985-4109-9380-ec908c8776dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found candidate data files in working directory:\n",
            " - breast-cancer-wisconsin.data\n",
            " - breast-cancer-wisconsin.data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating data loader data_prep.py**"
      ],
      "metadata": {
        "id": "yXKz1sdeBb-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > data_prep.py <<'PY'\n",
        "\"\"\"\n",
        "data_prep.py\n",
        "\n",
        "Robust loader for the UCI \"Breast Cancer Wisconsin (Original)\" dataset.\n",
        "- Accepts common file names or prompts upload in Colab\n",
        "- Drops ID column\n",
        "- Handles '?' missing values\n",
        "- Maps class 2->0 (benign), 4->1 (malignant)\n",
        "- Standardizes features (StandardScaler)\n",
        "- Returns X_train, X_test, y_train, y_test\n",
        "\"\"\"\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from io import StringIO\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "DEFAULT_FILENAMES = [\n",
        "    \"Breast_Cancer_Data.csv\",\n",
        "    \"breast-cancer-wisconsin.data\",\n",
        "    \"breast-cancer-wisconsin.data.txt\",\n",
        "    \"breast-cancer-wisconsin.data.csv\",\n",
        "    \"breast-cancer-wisconsin.data\"\n",
        "]\n",
        "\n",
        "def _find_file(provided_path=None):\n",
        "    if provided_path:\n",
        "        p = Path(provided_path)\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "\n",
        "    for name in DEFAULT_FILENAMES:\n",
        "        p = Path.cwd() / name\n",
        "        if p.exists():\n",
        "            return str(p)\n",
        "\n",
        "    for p in Path.cwd().glob(\"*breast*.*\"):\n",
        "        return str(p)\n",
        "\n",
        "    return None\n",
        "\n",
        "def _prompt_upload():\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"Please upload your dataset file (e.g. 'breast-cancer-wisconsin.data').\")\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded:\n",
        "            return fn\n",
        "    except Exception:\n",
        "        raise FileNotFoundError(\"Dataset not found in working directory and upload prompt unavailable.\")\n",
        "\n",
        "def load_data(path=None, test_size=0.25, random_state=42, standardize=True):\n",
        "    fp = _find_file(path)\n",
        "    if not fp:\n",
        "        fp = _prompt_upload()\n",
        "        if not fp:\n",
        "            raise FileNotFoundError(\"Dataset file could not be located or uploaded.\")\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(fp, header=None, sep=',', engine='python')\n",
        "    except Exception:\n",
        "        with open(fp, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            lines = [ln.rstrip('\\n') for ln in f if ln.strip() and ln.strip()[0].isdigit()]\n",
        "        if not lines:\n",
        "            raise ValueError(f\"No numeric data lines found in file {fp}. Please ensure you uploaded the correct dataset.\")\n",
        "        cleaned = StringIO(\"\\n\".join(lines))\n",
        "        try:\n",
        "            df = pd.read_csv(cleaned, header=None, sep=',', engine='python')\n",
        "        except Exception:\n",
        "            cleaned.seek(0)\n",
        "            df = pd.read_csv(cleaned, header=None, delim_whitespace=True, engine='python')\n",
        "\n",
        "    if df.shape[1] < 11:\n",
        "        raise ValueError(f\"Parsed data has {df.shape[1]} columns; expected at least 11. Check dataset format.\")\n",
        "    if df.shape[1] > 11:\n",
        "        df = df.iloc[:, :11]\n",
        "\n",
        "    df.columns = [\n",
        "        \"Sample_code_number\",\n",
        "        \"Clump_Thickness\",\n",
        "        \"Uniformity_Cell_Size\",\n",
        "        \"Uniformity_Cell_Shape\",\n",
        "        \"Marginal_Adhesion\",\n",
        "        \"Single_Epithelial_Cell_Size\",\n",
        "        \"Bare_Nuclei\",\n",
        "        \"Bland_Chromatin\",\n",
        "        \"Normal_Nucleoli\",\n",
        "        \"Mitoses\",\n",
        "        \"Class\"\n",
        "    ]\n",
        "\n",
        "    df = df.drop(columns=[\"Sample_code_number\"])\n",
        "\n",
        "    df.replace('?', np.nan, inplace=True)\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    before = len(df)\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    after = len(df)\n",
        "\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1].map({2: 0, 4: 1}).astype(int)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "\n",
        "    if standardize:\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "    return X_train, X_test, y_train.values, y_test.values, before, after\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    print(f\"Loaded data. Total rows before dropna: {before}, after dropna: {after}\")\n",
        "    print(\"Train/test shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "PY\n"
      ],
      "metadata": {
        "id": "sbw7MgQKApcn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating logistic_regression.py**"
      ],
      "metadata": {
        "id": "ydWP4581BiA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > logistic_regression.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = LogisticRegression(max_iter=2000, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== Logistic Regression ===\")\n",
        "    print(f\"Rows (before dropna): {before}, (after dropna): {after}\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"logistic_regression.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "B8I3CDsSAsgd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating knn.py (k = 5)**"
      ],
      "metadata": {
        "id": "HmqACNxQBmw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > knn.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== K-Nearest Neighbors (k=5) ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"knn_k5.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "GNIzyxrHBo-G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating svm_linear.py (linear kernel)**"
      ],
      "metadata": {
        "id": "lQxO-CZQBs08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > svm_linear.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = SVC(kernel='linear', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== SVM (linear kernel) ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"svm_linear.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "tOYhj_2ABsR4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating svm_rbf.py (RBF kernel)**"
      ],
      "metadata": {
        "id": "-x2OcKBCBwKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > svm_rbf.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = SVC(kernel='rbf', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== SVM (RBF kernel) ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"svm_rbf.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "wKbsSdmDBxrZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating naive_bayes.py**"
      ],
      "metadata": {
        "id": "fZ4FZjXbBzzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > naive_bayes.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = GaussianNB()\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== Gaussian Naive Bayes ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"naive_bayes.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "cG1HKCIGB1V3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating decision_tree.py**"
      ],
      "metadata": {
        "id": "z0GdvHKxB37m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > decision_tree.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = DecisionTreeClassifier(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== Decision Tree ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"decision_tree.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "7ceF3VVFB5Wb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating random_forest.py (n_estimators = 10)**"
      ],
      "metadata": {
        "id": "AbE8-Mf4B7tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > random_forest.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== Random Forest (n_estimators=10) ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"random_forest.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "eifwUCRoB96O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating xgboost_model.py**"
      ],
      "metadata": {
        "id": "j_JrrUR2CACp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > xgboost_model.py <<'PY'\n",
        "from data_prep import load_data\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "def run():\n",
        "    X_train, X_test, y_train, y_test, before, after = load_data()\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"=== XGBoost ===\")\n",
        "    print(f\"Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    joblib.dump(model, \"xgboost_model.pkl\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()\n",
        "PY\n"
      ],
      "metadata": {
        "id": "BTHL_GdhCBVC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Executing all model scripts (runs each .py and prints metrics)**"
      ],
      "metadata": {
        "id": "Ti-UT-RYCD4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "echo \"Running Logistic Regression...\"\n",
        "python3 logistic_regression.py || exit 1\n",
        "echo\n",
        "echo \"Running KNN (k=5)...\"\n",
        "python3 knn.py || exit 1\n",
        "echo\n",
        "echo \"Running SVM (linear)...\"\n",
        "python3 svm_linear.py || exit 1\n",
        "echo\n",
        "echo \"Running SVM (rbf)...\"\n",
        "python3 svm_rbf.py || exit 1\n",
        "echo\n",
        "echo \"Running Gaussian Naive Bayes...\"\n",
        "python3 naive_bayes.py || exit 1\n",
        "echo\n",
        "echo \"Running Decision Tree...\"\n",
        "python3 decision_tree.py || exit 1\n",
        "echo\n",
        "echo \"Running Random Forest...\"\n",
        "python3 random_forest.py || exit 1\n",
        "echo\n",
        "echo \"Running XGBoost...\"\n",
        "python3 xgboost_model.py || exit 1\n",
        "echo\n",
        "echo \"All models executed. Pickle files saved in working directory.\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42LpgoQxCEpY",
        "outputId": "f91d4d26-dc69-4d34-bfb2-3b0603c9ebbd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Logistic Regression...\n",
            "=== Logistic Regression ===\n",
            "Rows (before dropna): 699, (after dropna): 683\n",
            "Accuracy: 0.9591 (95.91%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  2  58]]\n",
            "\n",
            "Running KNN (k=5)...\n",
            "=== K-Nearest Neighbors (k=5) ===\n",
            "Accuracy: 0.9532 (95.32%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  3  57]]\n",
            "\n",
            "Running SVM (linear)...\n",
            "=== SVM (linear kernel) ===\n",
            "Accuracy: 0.9591 (95.91%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  2  58]]\n",
            "\n",
            "Running SVM (rbf)...\n",
            "=== SVM (RBF kernel) ===\n",
            "Accuracy: 0.9649 (96.49%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  1  59]]\n",
            "\n",
            "Running Gaussian Naive Bayes...\n",
            "=== Gaussian Naive Bayes ===\n",
            "Accuracy: 0.9591 (95.91%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  2  58]]\n",
            "\n",
            "Running Decision Tree...\n",
            "=== Decision Tree ===\n",
            "Accuracy: 0.9591 (95.91%)\n",
            "Confusion Matrix:\n",
            "[[105   6]\n",
            " [  1  59]]\n",
            "\n",
            "Running Random Forest...\n",
            "=== Random Forest (n_estimators=10) ===\n",
            "Accuracy: 0.9591 (95.91%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  2  58]]\n",
            "\n",
            "Running XGBoost...\n",
            "=== XGBoost ===\n",
            "Accuracy: 0.9708 (97.08%)\n",
            "Confusion Matrix:\n",
            "[[106   5]\n",
            " [  0  60]]\n",
            "\n",
            "All models executed. Pickle files saved in working directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:53:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Creating results_summary.csv with accuracy & confusion matrix for each model**"
      ],
      "metadata": {
        "id": "7yjygxL_CIMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from data_prep import load_data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test, _, _ = load_data()\n",
        "\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=2000, random_state=42),\n",
        "    \"KNN_k5\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM_linear\": SVC(kernel='linear', random_state=42),\n",
        "    \"SVM_rbf\": SVC(kernel='rbf', random_state=42),\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"RandomForest_n10\": RandomForestClassifier(n_estimators=10, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    rows.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": round(acc, 4),\n",
        "        \"Accuracy_pct\": round(acc*100, 2),\n",
        "        \"Confusion_Matrix\": str(cm.tolist())\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(rows)\n",
        "df_results.to_csv(\"results_summary.csv\", index=False)\n",
        "print(\"Created results_summary.csv. Preview:\")\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh2Vp2iRCJEa",
        "outputId": "1ad60a7c-0fbf-4bd4-9281-b6111c9bacbc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created results_summary.csv. Preview:\n",
            "                Model  Accuracy  Accuracy_pct     Confusion_Matrix\n",
            "0  LogisticRegression    0.9591         95.91  [[106, 5], [2, 58]]\n",
            "1              KNN_k5    0.9532         95.32  [[106, 5], [3, 57]]\n",
            "2          SVM_linear    0.9591         95.91  [[106, 5], [2, 58]]\n",
            "3             SVM_rbf    0.9649         96.49  [[106, 5], [1, 59]]\n",
            "4          GaussianNB    0.9591         95.91  [[106, 5], [2, 58]]\n",
            "5        DecisionTree    0.9591         95.91  [[105, 6], [1, 59]]\n",
            "6    RandomForest_n10    0.9591         95.91  [[106, 5], [2, 58]]\n",
            "7             XGBoost    0.9708         97.08  [[106, 5], [0, 60]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [08:53:31] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ]
    }
  ]
}